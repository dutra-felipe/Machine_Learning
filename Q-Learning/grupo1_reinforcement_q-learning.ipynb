{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zw_82AA87nfF",
    "outputId": "0519bcad-c98c-4628-882a-6aa6bb16309b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você começa.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sua jogada (0-8):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Você jogou:\n",
      " | | \n",
      "-----\n",
      " |X| \n",
      "-----\n",
      " | | \n",
      "-----\n",
      "\n",
      "Você jogou:\n",
      " | | \n",
      "-----\n",
      " |X| \n",
      "-----\n",
      " |O| \n",
      "-----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sua jogada (0-8):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Você jogou:\n",
      " | |X\n",
      "-----\n",
      " |X| \n",
      "-----\n",
      " |O| \n",
      "-----\n",
      "\n",
      "Você jogou:\n",
      " | |X\n",
      "-----\n",
      " |X|O\n",
      "-----\n",
      " |O| \n",
      "-----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sua jogada (0-8):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movimento inválido. Tente novamente.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sua jogada (0-8):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Você jogou:\n",
      " | |X\n",
      "-----\n",
      " |X|O\n",
      "-----\n",
      "X|O| \n",
      "-----\n",
      "Você venceu!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Parâmetros do Q-learning\n",
    "alpha = 0.5  # Taxa de aprendizado\n",
    "gamma = 0.9  # Fator de desconto\n",
    "epsilon = 1.0  # Probabilidade de exploração inicial (começa alta para explorar mais)\n",
    "min_epsilon = 0.01  # Limite mínimo para epsilon\n",
    "decay_rate = 0.9995  # Taxa de decaimento de epsilon para reduzir exploração com o tempo\n",
    "q_table = {}  # A tabela Q será inicializada conforme os estados aparecem\n",
    "\n",
    "# Funções auxiliares para o jogo da velha\n",
    "def initialize_board():\n",
    "    return [' '] * 9  # Usando uma lista compacta\n",
    "\n",
    "def print_board(board):\n",
    "    for row in [board[i:i+3] for i in range(0, 9, 3)]:\n",
    "        print('|'.join(row))\n",
    "        print(\"-\" * 5)\n",
    "\n",
    "def is_winner(board, player):\n",
    "    winning_combinations = [(0, 1, 2), (3, 4, 5), (6, 7, 8),\n",
    "                            (0, 3, 6), (1, 4, 7), (2, 5, 8),\n",
    "                            (0, 4, 8), (2, 4, 6)]\n",
    "    return any(board[a] == board[b] == board[c] == player for a, b, c in winning_combinations)\n",
    "\n",
    "def is_draw(board):\n",
    "    return ' ' not in board\n",
    "\n",
    "def available_actions(board):\n",
    "    return [i for i in range(9) if board[i] == ' ']\n",
    "\n",
    "def next_state(board, action, player):\n",
    "    new_board = board[:]\n",
    "    new_board[action] = player\n",
    "    return new_board\n",
    "\n",
    "# Função que escolhe a próxima ação do agente\n",
    "def choose_action(state, epsilon, player='X'):\n",
    "    actions = available_actions(state)\n",
    "    \n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.choice(actions)  # Exploração (jogada aleatória)\n",
    "    else:\n",
    "        # Exploração: usa a Q-Table para escolher a melhor jogada\n",
    "        q_values = [q_table.get((tuple(state), a), 0) for a in actions]\n",
    "        max_q_value = max(q_values)\n",
    "        \n",
    "        # Lista de ações com o mesmo valor máximo Q\n",
    "        best_actions = [actions[i] for i, q in enumerate(q_values) if q == max_q_value]\n",
    "        \n",
    "        return random.choice(best_actions)  # Escolhe aleatoriamente entre as melhores ações\n",
    "\n",
    "# Função que atualiza a tabela Q\n",
    "def update_q_table(state, action, reward, next_state, epsilon):\n",
    "    actions_next = available_actions(next_state)\n",
    "    next_max = max([q_table.get((tuple(next_state), a), 0) for a in actions_next], default=0)\n",
    "    \n",
    "    # Atualização da tabela Q\n",
    "    q_table[(tuple(state), action)] = q_table.get((tuple(state), action), 0) + \\\n",
    "                                      alpha * (reward + gamma * next_max - q_table.get((tuple(state), action), 0))\n",
    "\n",
    "# Função para treinar o agente\n",
    "def play_game(epsilon):\n",
    "\n",
    "    board = initialize_board()\n",
    "    state = board[:]\n",
    "\n",
    "    while True:\n",
    "        action = choose_action(state, epsilon, 'X')\n",
    "        next_board = next_state(state, action, 'X')\n",
    "\n",
    "        if is_winner(next_board, 'X'):\n",
    "            update_q_table(state, action, 1, next_board, epsilon)\n",
    "            break\n",
    "        elif is_draw(next_board):\n",
    "            update_q_table(state, action, 0, next_board, epsilon)\n",
    "            break\n",
    "        else:\n",
    "            update_q_table(state, action, 0, next_board, epsilon)\n",
    "\n",
    "        opponent_action = random.choice(available_actions(next_board))\n",
    "        next_board = next_state(next_board, opponent_action, 'O')\n",
    "\n",
    "        if is_winner(next_board, 'O'):\n",
    "            update_q_table(state, action, -1, next_board, epsilon)\n",
    "            break\n",
    "        elif is_draw(next_board):\n",
    "            update_q_table(state, action, 0, next_board, epsilon)\n",
    "            break\n",
    "\n",
    "        state = next_board[:]\n",
    "\n",
    "def play_turn(board, player, current_player, opponent):\n",
    "    state = board[:]\n",
    "\n",
    "    while True:\n",
    "        if current_player == 'Você':\n",
    "            # Jogador humano joga\n",
    "            while True:\n",
    "                try:\n",
    "                    player_action = int(input(\"Sua jogada (0-8): \"))\n",
    "                    if player_action in available_actions(state):\n",
    "                        next_board = next_state(state, player_action, player)\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Movimento inválido. Tente novamente.\")\n",
    "                except ValueError:\n",
    "                    print(\"Por favor, insira um número válido.\")\n",
    "\n",
    "            print(\"\\nVocê jogou:\")\n",
    "            print_board(next_board)\n",
    "\n",
    "            if is_winner(next_board, player):\n",
    "                print(\"Você venceu!\")\n",
    "                return\n",
    "            elif is_draw(next_board):\n",
    "                print(\"Empate!\")\n",
    "                return\n",
    "        else:\n",
    "            # Agente joga\n",
    "            action = choose_action(state, 0)  # Epsilon = 0 para jogar com a política aprendida\n",
    "            next_board = next_state(state, action, player)\n",
    "            print(f\"\\n{opponent} jogou:\")\n",
    "            print_board(next_board)\n",
    "\n",
    "            if is_winner(next_board, player):\n",
    "                print(f\"{opponent} venceu!\")\n",
    "                return\n",
    "            elif is_draw(next_board):\n",
    "                print(\"Empate!\")\n",
    "                return\n",
    "\n",
    "        # Alterna os jogadores\n",
    "        state = next_board[:]\n",
    "        if current_player == 'Você':\n",
    "            current_player, opponent = opponent, current_player\n",
    "            player = 'O' if player == 'X' else 'X'  # Alterna entre X e O\n",
    "        else:\n",
    "            current_player, opponent = opponent, current_player\n",
    "            player = 'O' if player == 'X' else 'X'\n",
    "\n",
    "def play_against_agent_random():\n",
    "    board = initialize_board()\n",
    "\n",
    "    # Sorteio para decidir quem começa\n",
    "    first_player = random.choice(['Voc'])\n",
    "    print(f\"{first_player} começa.\")\n",
    "\n",
    "    if first_player == 'Você':\n",
    "        # Você começa como X\n",
    "        play_turn(board, 'X', 'Você', 'Agente')\n",
    "    else:\n",
    "        # O agente começa como X\n",
    "        play_turn(board, 'O', 'Agente', 'Você')\n",
    "\n",
    "# Função para treinar o agente\n",
    "def train_agent(num_games):\n",
    "    global epsilon\n",
    "    for i in range(num_games):\n",
    "        play_game(epsilon)\n",
    "        # A redução do epsilon deve ser mais suave\n",
    "        epsilon = max(min_epsilon, epsilon * decay_rate)  # Decaimento mais lento de epsilon\n",
    "\n",
    "# Aumentando o número de jogos para um treinamento mais intenso\n",
    "train_agent(1000000)  # Aumente o número de jogos para melhorar o aprendizado\n",
    "\n",
    "play_against_agent_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Parâmetros do Q-learning\n",
    "alpha = 0.5  # Taxa de aprendizado\n",
    "gamma = 0.9  # Fator de desconto\n",
    "epsilon = 1  # Probabilidade de exploração inicial\n",
    "min_epsilon = 0.005  # Limite mínimo para epsilon\n",
    "decay_rate = 0.9995\n",
    "q_table = {}  # A tabela Q será inicializada conforme os estados aparecem\n",
    "\n",
    "# Funções auxiliares para o jogo da velha\n",
    "def initialize_board():\n",
    "    return [' '] * 9\n",
    "\n",
    "def print_board(board):\n",
    "    for row in [board[i:i+3] for i in range(0, 9, 3)]:\n",
    "        print('|'.join(row))\n",
    "        print(\"-\" * 5)\n",
    "\n",
    "def is_winner(board, player):\n",
    "    winning_combinations = [(0, 1, 2), (3, 4, 5), (6, 7, 8),\n",
    "                            (0, 3, 6), (1, 4, 7), (2, 5, 8),\n",
    "                            (0, 4, 8), (2, 4, 6)]\n",
    "    return any(board[a] == board[b] == board[c] == player for a, b, c in winning_combinations)\n",
    "\n",
    "def is_draw(board):\n",
    "    return ' ' not in board\n",
    "\n",
    "def available_actions(board):\n",
    "    return [i for i in range(9) if board[i] == ' ']\n",
    "\n",
    "def next_state(board, action, player):\n",
    "    new_board = board[:]\n",
    "    new_board[action] = player\n",
    "    return new_board\n",
    "\n",
    "# Função que escolhe a próxima ação do agente\n",
    "def choose_action(state, epsilon):\n",
    "    actions = available_actions(state)\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.choice(actions)\n",
    "    else:\n",
    "        q_values = [q_table.get((tuple(state), a), 0) for a in actions]\n",
    "        return actions[np.argmax(q_values)]\n",
    "\n",
    "# Função que atualiza a tabela Q\n",
    "def update_q_table(state, action, reward, next_state, epsilon):\n",
    "    actions_next = available_actions(next_state)\n",
    "    next_max = max([q_table.get((tuple(next_state), a), 0) for a in actions_next], default=0)\n",
    "    q_table[(tuple(state), action)] = q_table.get((tuple(state), action), 0) + alpha * (reward + gamma * next_max - q_table.get((tuple(state), action), 0))\n",
    "\n",
    "# Função para jogar uma partida completa com escolha aleatória de quem começa\n",
    "def play_against_agent_random():\n",
    "    board = initialize_board()\n",
    "\n",
    "    # Sorteio para decidir quem começa\n",
    "    first_player = random.choice(['Você', 'Agente'])\n",
    "    print(f\"{first_player} começa.\")\n",
    "\n",
    "    if first_player == 'Você':\n",
    "        # Você começa como X\n",
    "        play_turn(board, 'X', 'Você', 'Agente')\n",
    "    else:\n",
    "        # O agente começa como X\n",
    "        play_turn(board, 'O', 'Agente', 'Você')\n",
    "\n",
    "def play_turn(board, player, current_player, opponent):\n",
    "    state = board[:]\n",
    "\n",
    "    while True:\n",
    "        if current_player == 'Você':\n",
    "            # Jogador humano joga\n",
    "            while True:\n",
    "                try:\n",
    "                    player_action = int(input(\"Sua jogada (0-8): \"))\n",
    "                    if player_action in available_actions(state):\n",
    "                        next_board = next_state(state, player_action, player)\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Movimento inválido. Tente novamente.\")\n",
    "                except ValueError:\n",
    "                    print(\"Por favor, insira um número válido.\")\n",
    "\n",
    "            print(\"\\nVocê jogou:\")\n",
    "            print_board(next_board)\n",
    "\n",
    "            if is_winner(next_board, player):\n",
    "                print(\"Você venceu!\")\n",
    "                return\n",
    "            elif is_draw(next_board):\n",
    "                print(\"Empate!\")\n",
    "                return\n",
    "        else:\n",
    "            # Agente joga\n",
    "            action = choose_action(state, 0)  # Epsilon = 0 para jogar com a política aprendida\n",
    "            next_board = next_state(state, action, player)\n",
    "            print(f\"\\n{opponent} jogou:\")\n",
    "            print_board(next_board)\n",
    "\n",
    "            if is_winner(next_board, player):\n",
    "                print(f\"{opponent} venceu!\")\n",
    "                return\n",
    "            elif is_draw(next_board):\n",
    "                print(\"Empate!\")\n",
    "                return\n",
    "\n",
    "        # Alterna os jogadores\n",
    "        state = next_board[:]\n",
    "        if current_player == 'Você':\n",
    "            current_player, opponent = opponent, current_player\n",
    "            player = 'O' if player == 'X' else 'X'  # Alterna entre X e O\n",
    "        else:\n",
    "            current_player, opponent = opponent, current_player\n",
    "            player = 'O' if player == 'X' else 'X'\n",
    "\n",
    "# Função para treinar o agente sem interação (simulação)\n",
    "def play_game(epsilon):\n",
    "    board = initialize_board()\n",
    "    state = board[:]\n",
    "\n",
    "    while True:\n",
    "        # Jogador X (agente) joga\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_board = next_state(state, action, 'X')\n",
    "\n",
    "        if is_winner(next_board, 'X'):\n",
    "            update_q_table(state, action, 2, next_board, epsilon)  # Vitória do X\n",
    "            break\n",
    "        elif is_draw(next_board):\n",
    "            update_q_table(state, action, 1, next_board, epsilon)  # Empate\n",
    "            break\n",
    "        else:\n",
    "            update_q_table(state, action, -0.2, next_board, epsilon)  # Jogo continua\n",
    "\n",
    "        # Oponente joga (jogador O - aleatório)\n",
    "        opponent_action = random.choice(available_actions(next_board))\n",
    "        next_board = next_state(next_board, opponent_action, 'O')\n",
    "\n",
    "        if is_winner(next_board, 'O'):\n",
    "            update_q_table(state, action, -1, next_board, epsilon)  # Derrota de X\n",
    "            break\n",
    "        elif is_draw(next_board):\n",
    "            update_q_table(state, action, 1, next_board, epsilon)  # Empate\n",
    "            break\n",
    "\n",
    "        # Passa para o próximo estado\n",
    "        state = next_board[:]\n",
    "\n",
    "# Treinamento do agente\n",
    "def train_agent(num_games):\n",
    "    global epsilon\n",
    "    for i in range(num_games):\n",
    "        play_game(epsilon)\n",
    "        epsilon *= decay_rate  # Decaimento de epsilon para reduzir a exploração\n",
    "\n",
    "# Treinando o agente\n",
    "train_agent(10000000)  # Treina o agente com 10.000.000 partidas\n",
    "\n",
    "# Agora você pode jogar contra o agente com chance aleatória de começar\n",
    "play_against_agent_random()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
